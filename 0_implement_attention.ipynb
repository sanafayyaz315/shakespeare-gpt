{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Attention in Transformers  \n",
    "This notebook demonstrates **self-attention** (used in GPT-like models) with a minimal example. Inspired by [Andrej Karpathy's lecture](https://youtu.be/kCc8FmEb1nY), we'll:  \n",
    "1. Create toy embeddings for a sentence.  \n",
    "2. Compute attention scores (weights) between tokens.  \n",
    "3. Mask future tokens for autoregressive (causal) attention.  \n",
    "4. Aggregate embeddings using weighted sums.  \n",
    "\n",
    "Key idea: Each token's output is a weighted mix of *itself* and *past tokens*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Attention?  \n",
    "Language models predict the next word by focusing on relevant past words. Consider a string \"your cat is a lovely cat\": \n",
    "- The first \"cat\" might attend to \"your\".  \n",
    "- The second \"cat\" might attend to \"your lovely\".  \n",
    "Attention weights (`wei`) decide how much focus each word gets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Toy Embeddings  \n",
    "We'll use a tiny sentence and map each word to a random 2D embedding (for visualization).  \n",
    "- `stoi`: Word-to-index mapping.  \n",
    "- `embedding_table`: Random embeddings (normally learned during training).  \n",
    "\n",
    "For understanding, let's work with the string *\"your cat is a lovely cat\"* as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string to int mapping:\n",
      " {'your': 0, 'cat': 5, 'is': 2, 'a': 3, 'lovely': 4}\n",
      "tokenized input:\n",
      " tensor([0, 5, 2, 3, 4, 5])\n",
      "embedded input:\n",
      " tensor([[-2.0260, -2.0655],\n",
      "        [ 0.5133,  0.3319],\n",
      "        [-1.2502,  0.8032],\n",
      "        [-0.2071,  0.0544],\n",
      "        [ 0.1378, -0.3889],\n",
      "        [ 0.5133,  0.3319]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed random seed for reproducibility (ensures consistent embeddings)\n",
    "torch.manual_seed(1337);\n",
    "\n",
    "# Sample sentence (6 tokens)\n",
    "s = \"your cat is a lovely cat\"\n",
    "\n",
    "# word-to-index mapping (vocabulary)\n",
    "stoi = {c:n for n, c in enumerate(s.split(\" \"))}\n",
    "print(f\"string to int mapping:\\n {stoi}\")\n",
    "\n",
    "# tokenize s\n",
    "x = torch.tensor([stoi[c] for c in s.split(\" \")])\n",
    "print(f\"tokenized input:\\n {x}\")\n",
    "\n",
    "# embed x (tokenized s) into 2 dims\n",
    "embedding_table = nn.Embedding(6, 2)\n",
    "x = embedding_table(x)\n",
    "print(f\"embedded input:\\n {x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower triangular matrix:\n",
      " tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "initialized weight matrix:\n",
      " tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "masked wei matrix:\n",
      " tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "normalized wei matrix\n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]]) with shape torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "# create a lower triangular matrix where lower tri is 1 and upper 0\n",
    "tril = torch.tril(torch.ones(6, 6))\n",
    "print(f\"lower triangular matrix:\\n {tril}\")\n",
    "# a weight matrix of (vocab_size, vocab_size) initialized with zeros \n",
    "wei = torch.zeros((6,6))\n",
    "print(f\"initialized weight matrix:\\n {wei}\")\n",
    "# fill the upper half of the matrix with -inf where tril has 0s to mask the future tokens\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "print(f\"masked wei matrix:\\n {wei}\")\n",
    "# softmax normalizes(converts into probs that sum up to 1)\n",
    "wei = F.softmax(wei, dim=1) \n",
    "print(f\"normalized wei matrix\\n {wei} with shape {wei.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Weights (`wei`)  \n",
    "The `wei` matrix defines how much each token (row) attends to others (columns):  \n",
    "- **Lower triangular**: Tokens only attend to past/current tokens (causal masking).  \n",
    "- **Uniform weights**: Because we initialized `wei` as `-inf` (masked) or `0` (unmasked), softmax gives equal weight to all unmasked tokens.  \n",
    "\n",
    "Example:  \n",
    "- Row 0 (`[1, 0, 0,...]`): First token (\"your\") only attends to itself.  \n",
    "- Row 2 (`[0.33, 0.33, 0.33,...]`): Third token (\"is\") averages itself + past tokens (\"your\", \"cat\"), so it only attends to the current token \"cat\" and the previous token \"your\" while probability for the future tokens is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wei matrix calculates the attention score - it tells you much focus a word should place on the other words/tokens\n",
    "Each row corresponds to a word position\n",
    "\n",
    "Each column shows how much attention to give to previous words\n",
    "\n",
    "Because we initialized the wei to 0, every token pays equal attention to itself and all the tokens that came before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.0260, -2.0655],\n",
       "         [ 0.5133,  0.3319],\n",
       "         [-1.2502,  0.8032],\n",
       "         [-0.2071,  0.0544],\n",
       "         [ 0.1378, -0.3889],\n",
       "         [ 0.5133,  0.3319]], grad_fn=<EmbeddingBackward0>),\n",
       " torch.Size([6, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape # your cat is a lovely cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei matrix:\n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]])\n",
      "input x:\n",
      " tensor([[-2.0260, -2.0655],\n",
      "        [ 0.5133,  0.3319],\n",
      "        [-1.2502,  0.8032],\n",
      "        [-0.2071,  0.0544],\n",
      "        [ 0.1378, -0.3889],\n",
      "        [ 0.5133,  0.3319]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"wei matrix:\\n {wei}\")\n",
    "print(f\"input x:\\n {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Contextual Embeddings  \n",
    "Now we compute the **weighted sum** of embeddings using `wei`:  \n",
    "$$  \n",
    "\\text{out}_i = \\sum_{j \\leq i} \\text{wei}_{ij} \\cdot x_j  \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6]) torch.Size([6, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.0260, -2.0655],\n",
       "         [-0.7563, -0.8668],\n",
       "         [-0.9210, -0.3101],\n",
       "         [-0.7425, -0.2190],\n",
       "         [-0.5664, -0.2530],\n",
       "         [-0.3865, -0.1555]], grad_fn=<MmBackward0>),\n",
       " torch.Size([6, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wei.shape, x.shape) # wei gives equal importance to the current and the past tokens\n",
    "out = wei @ x \n",
    "# we aggregate each token embedding (x) with the average of the token itself and the past tokens\n",
    "out, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wei @ x is basically taking the sum of the embeddings of all the previous tokens, weighted by the attention weights. (weighted sum)\n",
    "$$\n",
    "\\text{out}_i = \\sum_{j=1}^{n} \\alpha_{ij} \\cdot V_j\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    "α \n",
    "ij\n",
    "​\n",
    " : how much token i attends to token j (computed via softmax)\n",
    "\n",
    "V \n",
    "j\n",
    "​\n",
    " : the value vector of token j\n",
    "\n",
    "\n",
    "out \n",
    "i\n",
    "​\n",
    " : new embedding of token i after considering context\n",
    "\n",
    "This is a weighted sum over all other tokens’ value vectors V j\n",
    "​\n",
    " ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in out is a new vector representation of a word, but now it has context.\n",
    "\n",
    "Originally, each word had its own isolated embedding (just from the nn.Embedding table).\n",
    "\n",
    "Now, after wei @ x, each word's vector is a weighted average of itself and its previous words.\n",
    "\n",
    "This means:\n",
    "\n",
    "The word's new representation encodes its meaning in context, based only on past tokens (left-to-right), like a causal language model.\n",
    "\n",
    "out[0]: representation of \"your\" (just its embedding)\n",
    "\n",
    "out[1]: representation of \"cat\" as a mixture of \"your\" and \"cat\"\n",
    "\n",
    "out[2]: representation of \"is\" based on \"your\", \"cat\", and \"is\"\n",
    "\n",
    "...\n",
    "\n",
    "out[5]: representation of the final \"cat\", which now depends on all previous words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Attention  \n",
    "The heatmap shows how much each query token (row) attends to key tokens (columns). Note the lower-triangular pattern (no future peeking!):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "####  Add Visualization (Critical for Intuition)**  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(wei.detach().numpy(), cmap='Blues')\n",
    "plt.xlabel(\"Key Position\")\n",
    "plt.ylabel(\"Query Position\")\n",
    "plt.title(\"Attention Weights\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Query, Key, Value (QKV) Attention  \n",
    "Real attention uses learned **Query** (what I’m looking for), **Key** (what I contain), and **Value** (what I’ll share) vectors:  \n",
    "- `q = query(x)`: How much the token \"asks\" about others.  \n",
    "- `k = key(x)`: How much the token \"answers\" others' queries.  \n",
    "- `v = value(x)`: Actual content shared.  \n",
    "\n",
    "Scores (`wei = q @ k.T`) measure query-key compatibility.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input: torch.Size([6, 2])\n",
      "Query for all the 6 tokens: tensor([[-0.8880,  1.9067],\n",
      "        [ 0.1336, -0.4055],\n",
      "        [ 0.4446,  0.3338],\n",
      "        [ 0.0361,  0.0872],\n",
      "        [-0.1925,  0.0850],\n",
      "        [ 0.1336, -0.4055]], grad_fn=<MmBackward0>), shape: torch.Size([6, 2])\n",
      "Key for all the 6 tokens: tensor([[ 0.7013, -2.1317],\n",
      "        [-0.2415,  0.4191],\n",
      "        [ 1.1257, -0.0024],\n",
      "        [ 0.1603, -0.0501],\n",
      "        [-0.2243, -0.1895],\n",
      "        [-0.2415,  0.4191]], grad_fn=<MmBackward0>), shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "head_size = 2\n",
    "key = nn.Linear(2, head_size, bias=False)\n",
    "query = nn.Linear(2, head_size, bias=False)\n",
    "value = nn.Linear(2, head_size, bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "v = value(x)\n",
    "print(f\"shape of input: {x.shape}\")\n",
    "print(f\"Query for all the 6 tokens: {q}, shape: {q.shape}\")\n",
    "print(f\"Key for all the 6 tokens: {k}, shape: {k.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7013, -0.2415,  1.1257,  0.1603, -0.2243, -0.2415],\n",
       "        [-2.1317,  0.4191, -0.0024, -0.0501, -0.1895,  0.4191]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-4.6874e+00,  1.0137e+00, -1.0042e+00, -2.3785e-01, -1.6225e-01,\n",
       "           1.0137e+00],\n",
       "         [ 9.5800e-01, -2.0221e-01,  1.5131e-01,  4.1719e-02,  4.6900e-02,\n",
       "          -2.0221e-01],\n",
       "         [-3.9978e-01,  3.2535e-02,  4.9966e-01,  5.4525e-02, -1.6298e-01,\n",
       "           3.2535e-02],\n",
       "         [-1.6059e-01,  2.7838e-02,  4.0407e-02,  1.4131e-03, -2.4621e-02,\n",
       "           2.7838e-02],\n",
       "         [-3.1625e-01,  8.2131e-02, -2.1689e-01, -3.5109e-02,  2.7054e-02,\n",
       "           8.2131e-02],\n",
       "         [ 9.5800e-01, -2.0221e-01,  1.5131e-01,  4.1719e-02,  4.6900e-02,\n",
       "          -2.0221e-01]], grad_fn=<MmBackward0>),\n",
       " torch.Size([6, 6]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = q @ k.T # dot product the query of each token with the key of itself and all the other tokens \n",
    "wei, wei.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking Future Tokens  \n",
    "To prevent cheating in autoregressive models (like GPT), we mask future tokens by setting their scores to `-inf` before softmax:  \n",
    "```python  \n",
    "tril = torch.tril(torch.ones(6, 6))  # Lower triangular mask  \n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix: tensor([[-4.6874e+00,        -inf,        -inf,        -inf,        -inf,\n",
      "                -inf],\n",
      "        [ 9.5800e-01, -2.0221e-01,        -inf,        -inf,        -inf,\n",
      "                -inf],\n",
      "        [-3.9978e-01,  3.2535e-02,  4.9966e-01,        -inf,        -inf,\n",
      "                -inf],\n",
      "        [-1.6059e-01,  2.7838e-02,  4.0407e-02,  1.4131e-03,        -inf,\n",
      "                -inf],\n",
      "        [-3.1625e-01,  8.2131e-02, -2.1689e-01, -3.5109e-02,  2.7054e-02,\n",
      "                -inf],\n",
      "        [ 9.5800e-01, -2.0221e-01,  1.5131e-01,  4.1719e-02,  4.6900e-02,\n",
      "         -2.0221e-01]], grad_fn=<MaskedFillBackward0>)\n",
      "score: tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7614, 0.2386, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.3082, 0.4917, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2171, 0.2621, 0.2655, 0.2553, 0.0000, 0.0000],\n",
      "        [0.1580, 0.2354, 0.1745, 0.2093, 0.2228, 0.0000],\n",
      "        [0.3478, 0.1090, 0.1552, 0.1391, 0.1398, 0.1090]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "output: tensor([[ 0.9757, -0.4630],\n",
      "        [ 0.6924, -0.3358],\n",
      "        [ 0.2349,  0.0416],\n",
      "        [ 0.2258, -0.0167],\n",
      "        [ 0.1594, -0.0351],\n",
      "        [ 0.3379, -0.1216]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# mask the weights for the futire tokens\n",
    "tril = torch.tril(torch.ones(6,6))\n",
    "wei = wei.masked_fill(tril ==0, float(\"-inf\"))\n",
    "print(f\"weight matrix: {wei}\")\n",
    "# apply softmax to get the attention score\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(f\"score: {wei}\")\n",
    "out = wei @ v\n",
    "print(f\"output: {out}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values (no context):\\n tensor([[ 0.9757, -0.4630],\n",
      "        [-0.2114,  0.0699],\n",
      "        [ 0.2133,  0.2291],\n",
      "        [ 0.0501,  0.0185],\n",
      "        [ 0.0327, -0.0997],\n",
      "        [-0.2114,  0.0699]], grad_fn=<MmBackward0>)\n",
      "Contextualized outputs:\\n tensor([[ 0.9757, -0.4630],\n",
      "        [ 0.6924, -0.3358],\n",
      "        [ 0.2349,  0.0416],\n",
      "        [ 0.2258, -0.0167],\n",
      "        [ 0.1594, -0.0351],\n",
      "        [ 0.3379, -0.1216]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compare original vs. contextualized embeddings:  \n",
    "# - `v`: Isolated token representations.  \n",
    "# - `out`: Tokens now include context from previous words.  \n",
    "print(\"Original values (no context):\\\\n\", v)  \n",
    "print(\"Contextualized outputs:\\\\n\", out)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output  \n",
    "Each row in `out` is a new embedding combining information from past tokens via attention. Compare:  \n",
    "- `v`: Original value vectors (no context).  \n",
    "- `out`: Contextualized vectors (e.g., the second \"cat\" now knows about the first \"cat\").  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways  \n",
    "- Attention computes weighted sums of embeddings.  \n",
    "- Masking ensures causality (no future peeking).  \n",
    "- Q/K/V projections enable dynamic context mixing.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
